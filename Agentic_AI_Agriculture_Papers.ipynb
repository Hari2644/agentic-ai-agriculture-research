{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOL76o0ib5wihVvfSXriywB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"9wOVeGALa25l","executionInfo":{"status":"ok","timestamp":1770439656235,"user_tz":-330,"elapsed":203,"user":{"displayName":"Harika Jaggavarapu","userId":"11466547513809887992"}}},"outputs":[],"source":["import requests\n","import xml.etree.ElementTree as ET\n","from datetime import datetime\n"]},{"cell_type":"code","source":["def search_arxiv_papers(query, max_results=3):\n","    base_url = \"http://export.arxiv.org/api/query?\"\n","    search_query = f\"search_query=all:{query}&start=0&max_results={max_results}&sortBy=submittedDate&sortOrder=descending\"\n","    response = requests.get(base_url + search_query)\n","\n","    root = ET.fromstring(response.content)\n","\n","    papers = []\n","    for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):\n","        title = entry.find('{http://www.w3.org/2005/Atom}title').text.strip()\n","        summary = entry.find('{http://www.w3.org/2005/Atom}summary').text.strip()\n","        published = entry.find('{http://www.w3.org/2005/Atom}published').text\n","        link = entry.find('{http://www.w3.org/2005/Atom}id').text\n","\n","        papers.append({\n","            \"title\": title,\n","            \"summary\": summary,\n","            \"published\": published,\n","            \"link\": link\n","        })\n","\n","    return papers\n"],"metadata":{"id":"weXm8fFBbXX5","executionInfo":{"status":"ok","timestamp":1770439672665,"user_tz":-330,"elapsed":5,"user":{"displayName":"Harika Jaggavarapu","userId":"11466547513809887992"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["papers = search_arxiv_papers(\"agriculture artificial intelligence\", 3)\n","papers\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9sRyDENUbaxX","executionInfo":{"status":"ok","timestamp":1770439687768,"user_tz":-330,"elapsed":1040,"user":{"displayName":"Harika Jaggavarapu","userId":"11466547513809887992"}},"outputId":"82d2d4b0-51e3-433f-ab72-89298559f18d"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'title': 'Shared LoRA Subspaces for almost Strict Continual Learning',\n","  'summary': 'Adapting large pretrained models to new tasks efficiently and continually is crucial for real-world deployment but remains challenging due to catastrophic forgetting and the high cost of retraining. While parameter-efficient tuning methods like low rank adaptation (LoRA) reduce computational demands, they lack mechanisms for strict continual learning and knowledge integration, without relying on data replay, or multiple adapters. We propose Share, a novel approach to parameter efficient continual finetuning that learns and dynamically updates a single, shared low-rank subspace, enabling seamless adaptation across multiple tasks and modalities. Share constructs a foundational subspace that extracts core knowledge from past tasks and incrementally integrates new information by identifying essential subspace directions. Knowledge from each new task is incorporated into this evolving subspace, facilitating forward knowledge transfer, while minimizing catastrophic interference. This approach achieves up to 100x parameter reduction and 281x memory savings over traditional LoRA methods, maintaining performance comparable to jointly trained models. A single Share model can replace hundreds of task-specific LoRA adapters, supporting scalable, asynchronous continual learning. Experiments across image classification, natural language understanding, 3D pose estimation, and text-to-image generation validate its effectiveness, making Share a practical and scalable solution for lifelong learning in large-scale AI systems.',\n","  'published': '2026-02-05T18:59:58Z',\n","  'link': 'http://arxiv.org/abs/2602.06043v1'},\n"," {'title': 'DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic Matching',\n","  'summary': \"Multi-agent systems built from prompted large language models can improve multi-round reasoning, yet most existing pipelines rely on fixed, trajectory-wide communication patterns that are poorly matched to the stage-dependent needs of iterative problem solving. We introduce DyTopo, a manager-guided multi-agent framework that reconstructs a sparse directed communication graph at each round. Conditioned on the manager's round goal, each agent outputs lightweight natural-language query (need) and \\\\key (offer) descriptors; DyTopo embeds these descriptors and performs semantic matching, routing private messages only along the induced edges. Across code generation and mathematical reasoning benchmarks and four LLM backbones, DyTopo consistently outperforms over the strongest baseline (avg. +6.2). Beyond accuracy, DyTopo yields an interpretable coordination trace via the evolving graphs, enabling qualitative inspection of how communication pathways reconfigure across rounds.\",\n","  'published': '2026-02-05T18:59:51Z',\n","  'link': 'http://arxiv.org/abs/2602.06039v1'},\n"," {'title': 'CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction',\n","  'summary': 'To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, effective information gathering is important in completing these assignments. To address this component of the problem, we formalize the information-gathering process in a fully cooperative setting as an underexplored multi-agent multi-task Embodied Question Answering (MM-EQA) problem, which is a novel extension of canonical Embodied Question Answering (EQA), where effective communication is crucial for coordinating efforts without redundancy. To address this problem, we propose CommCP, a novel LLM-based decentralized communication framework designed for MM-EQA. Our framework employs conformal prediction to calibrate the generated messages, thereby minimizing receiver distractions and enhancing communication reliability. To evaluate our framework, we introduce an MM-EQA benchmark featuring diverse, photo-realistic household scenarios with embodied questions. Experimental results demonstrate that CommCP significantly enhances the task success rate and exploration efficiency over baselines. The experiment videos, code, and dataset are available on our project website: https://comm-cp.github.io.',\n","  'published': '2026-02-05T18:59:45Z',\n","  'link': 'http://arxiv.org/abs/2602.06038v1'}]"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["def summarize_text(text, max_sentences=3):\n","    sentences = text.split('. ')\n","    summary = '. '.join(sentences[:max_sentences])\n","    return summary.strip() + '.'\n"],"metadata":{"id":"Xorlt-Uxbfet","executionInfo":{"status":"ok","timestamp":1770439705566,"user_tz":-330,"elapsed":15,"user":{"displayName":"Harika Jaggavarapu","userId":"11466547513809887992"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["for paper in papers:\n","    paper[\"summary\"] = summarize_text(paper[\"summary\"])\n"],"metadata":{"id":"eE2MIQ0bbinl","executionInfo":{"status":"ok","timestamp":1770439718534,"user_tz":-330,"elapsed":63,"user":{"displayName":"Harika Jaggavarapu","userId":"11466547513809887992"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def store_results(papers):\n","    memory = []\n","    for p in papers:\n","        memory.append({\n","            \"title\": p[\"title\"],\n","            \"published_date\": p[\"published\"],\n","            \"summary\": p[\"summary\"],\n","            \"link\": p[\"link\"]\n","        })\n","    return memory\n"],"metadata":{"id":"2DttaS7ablUQ","executionInfo":{"status":"ok","timestamp":1770439729453,"user_tz":-330,"elapsed":12,"user":{"displayName":"Harika Jaggavarapu","userId":"11466547513809887992"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def agent_execute(user_goal):\n","    plan = [\n","        \"Search recent AI research papers related to agriculture\",\n","        \"Summarize the research papers\",\n","        \"Store results in structured format\"\n","    ]\n","\n","    print(\"AGENT PLAN:\")\n","    for step in plan:\n","        print(\"-\", step)\n","\n","    papers = search_arxiv_papers(\"agriculture artificial intelligence\", 3)\n","\n","    for paper in papers:\n","        paper[\"summary\"] = summarize_text(paper[\"summary\"])\n","\n","    memory = store_results(papers)\n","\n","    return memory\n"],"metadata":{"id":"hC8xQNe6boRH","executionInfo":{"status":"ok","timestamp":1770439741518,"user_tz":-330,"elapsed":5,"user":{"displayName":"Harika Jaggavarapu","userId":"11466547513809887992"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["user_goal = \"Find the top 3 recent AI research papers on agriculture, summarize them, and store the output in a structured format.\"\n","\n","final_output = agent_execute(user_goal)\n","final_output\n"],"metadata":{"id":"WgLdQqofbrXe","executionInfo":{"status":"ok","timestamp":1770439754510,"user_tz":-330,"elapsed":94,"user":{"displayName":"Harika Jaggavarapu","userId":"11466547513809887992"}},"outputId":"3a695e9f-e6d6-4197-d1be-2c757db8fc51","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["AGENT PLAN:\n","- Search recent AI research papers related to agriculture\n","- Summarize the research papers\n","- Store results in structured format\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'title': 'Shared LoRA Subspaces for almost Strict Continual Learning',\n","  'published_date': '2026-02-05T18:59:58Z',\n","  'summary': 'Adapting large pretrained models to new tasks efficiently and continually is crucial for real-world deployment but remains challenging due to catastrophic forgetting and the high cost of retraining. While parameter-efficient tuning methods like low rank adaptation (LoRA) reduce computational demands, they lack mechanisms for strict continual learning and knowledge integration, without relying on data replay, or multiple adapters. We propose Share, a novel approach to parameter efficient continual finetuning that learns and dynamically updates a single, shared low-rank subspace, enabling seamless adaptation across multiple tasks and modalities.',\n","  'link': 'http://arxiv.org/abs/2602.06043v1'},\n"," {'title': 'DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic Matching',\n","  'published_date': '2026-02-05T18:59:51Z',\n","  'summary': \"Multi-agent systems built from prompted large language models can improve multi-round reasoning, yet most existing pipelines rely on fixed, trajectory-wide communication patterns that are poorly matched to the stage-dependent needs of iterative problem solving. We introduce DyTopo, a manager-guided multi-agent framework that reconstructs a sparse directed communication graph at each round. Conditioned on the manager's round goal, each agent outputs lightweight natural-language query (need) and \\\\key (offer) descriptors; DyTopo embeds these descriptors and performs semantic matching, routing private messages only along the induced edges.\",\n","  'link': 'http://arxiv.org/abs/2602.06039v1'},\n"," {'title': 'CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction',\n","  'published_date': '2026-02-05T18:59:45Z',\n","  'summary': 'To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, effective information gathering is important in completing these assignments.',\n","  'link': 'http://arxiv.org/abs/2602.06038v1'}]"]},"metadata":{},"execution_count":8}]}]}